
# Multiple Regression

This week we'll continue with the videos from Andrew Ng's great Machine
Learning course on Coursera:

## Linear Regression with Multiple Variables

### Multiple features

![embed](https://www.youtube.com/embed/jXg0vU0y1ak)

### Vectorization part 1

![embed](https://www.youtube.com/embed/U6zuBcmLxSg)

### Vectorization part 2

![embed](https://www.youtube.com/embed/uvTL1N02f04)

### Gradient Descent for Multiple Regression

![embed](https://www.youtube.com/embed/YjpCQof9tI8)

### Feature Scaling part 1

![embed](https://www.youtube.com/embed/YVtP5UGdgXg)

### Feature Scaling part 2

![embed](https://www.youtube.com/embed/gmJqLGrUscg)

### Checking Gradient Descent for Convergence

![embed](https://www.youtube.com/embed/5g4H5_gsTpU)

### Choosing the Learning Rate

![embed](https://www.youtube.com/embed/P_9hNBVRldM)

### Feature Engineering

![embed](https://www.youtube.com/embed/ecOdZlY9jsQ)

### Polynomial Regression

![embed](https://www.youtube.com/embed/IFkRKJ5iBDE)

## Overfitting

This last video will come back later in the course, but covers
a topic that will already be very relevant to the assignment
this week, namely *overfitting*. You can skip the last part
about classification, as we have not covered logistic
regression yet.

![embed](https://www.youtube.com/embed/NIiZZY7nlfU)

