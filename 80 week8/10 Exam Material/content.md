
# Exam Material

The material for the exam consists of everything covered in the theory videos
and programming notebooks for this course. The focus for the exam will be on
understanding of the material, not memorization of equations. This means you
will not be asked to the reproduce equations for some algorithm, but you might
be shown an equation and asked to explain what all the terms are and how they
relate to some piece of machine learning theory. 

This means the theory pages from the SOWISO and the articles from the writing
assignment are *not* part of the exam material, in the sense that will not be
asked about any of these directly. However, you are expected to be able to
relate these concepts back to the machine learning theory, as described above.
This means that you won't be asked to take a derivative of some function, but
you might be asked to explain what the gradient is and how it can be used to
optimize the cost function of some model. 

## Covered algorithms

* Supervised Learning - Regression
    * Univariate Linear
    * Multivariate Linear
    * Univariate Polynomial
* Supervised Learning - Classification
    * k-Nearest Neighbours
    * Naive Bayes
    * Logistic Regression
* Unsupervised Learning - Clustering
    * k-Means

## Outline of the exam

For the first 5/10 minutes of the exam, you're expected to explain one of the
covered algorithms, as listed above, to us. You can choose this algorithm
yourself beforehand, and may even make slides or other visuals, if you'd like,
although this is not required. The requirement here is simply for you to
explain one these 7 listed algorithms.

Afterward, we'll ask some follow-up questions about your selected algorithm. If
you selected an easy algorithm, like univariate linear or k-NN, these questions
might be harder than if you select a more difficult to explain algorithm.
Finally, there will also be some open questions on general machine learning
theory and one or two other algorithms.

We'll immediately let you know if you've passed, but won't publish the grades
until after everyone has completed (and passed) their exams.

## Additional material

The hundred-page machine learning book, by Andriy Burkov, is a compact 100 page
introduction to machine learning. It is a little more mathematical than most of
the material in this course, but it does give a nice complete overview. It
includes the general notion of machine learning, required mathematical tools
and some of the algorithms, so the book might be useful to use as review.

Burkov offers the first 34 pages of the book online for free, which you can
find below. We've covered most of the topics in these first 34 pages, although
some, like *Support Vector Machines* and *Decision Trees* will be
**Introduction to Machine Learning 2** material.

[The hundred-page machine learning book (sample)](theMLbook-sample.pdf)

If you like the way the material is presented in this book and would like to
read the remaining 66 pages, you can buy the book
[here](http://themlbook.com/).

